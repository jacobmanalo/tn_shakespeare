# TN Shakespeare

Here, I take a simple Shakespeare GPT model that outputs random text in the style of Shakespeare and apply tensor network decomposition to each layer resulting in a model that contains 80% less parameters and maintains accuracy within 2%.
